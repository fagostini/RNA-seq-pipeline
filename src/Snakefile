import os
import platform
import pandas as pd
import numpy as np
import string

# from snakemake.remote.HTTP import RemoteProvider as HTTPRemoteProvider
# HTTP = HTTPRemoteProvider()

# Import config file & parameters
configfile: 'config.yaml'

# Import paths from config file
workdir: config['snakemake_path']
RESULTS_PATH = config['results_path']
GENOME_PATH = config['genome_path']
ANNOTATION_PATH = config['annotation_path']
STAR_INDEX_PATH = config['star_index_path']

def platform_info():
	import platform
	if platform.system() in "Darwin":
		return(".".join(("macOS", platform.machine())))
	else:
		return(".".join((platform.system().lower(), platform.machine())))

rule all:
	input:
		"report.html"

def rename_out(inlist, suffix, outdir, outlist):
	for i in range(len(inlist)):
		base_out = "/".join((outdir, os.path.basename(inlist[i])))
		temp_out = "".join((base_out.partition(".")[0], suffix[0] if len(suffix)==1 else suffix[i]))
		print(" ".join(("mv", temp_out, outlist[i])))
		os.system(" ".join(("mv", temp_out, outlist[i])))

rule fastqc_se_pre:
	input:
		fastq=lambda wildcards: config["samples"][wildcards.sample]
	output:
		html=expand(RESULTS_PATH+"/fastqc-pre/{{sample}}_{ext}_fastqc.html", ext=["SE"]),
		gzip=temp(expand(RESULTS_PATH+"/fastqc-pre/{{sample}}_{ext}_fastqc.zip", ext=["SE"]))
	params:
		outdir=RESULTS_PATH+"/fastqc-pre",
		cluster='-N 1 -c 1 --mem=8G -t 160:00:00 -o {}/logs/fastqc-pre.{{sample}}.%A.log'.format(RESULTS_PATH)
	log:
		RESULTS_PATH+"/logs/fastqc-pre/{sample}.txt"
	threads:
		1
	run:
		shell("fastqc -t {threads} --outdir {params.outdir} {input.fastq} 2>&1 > {log}")
		rename_out(input["fastq"], ["_fastqc.html"], params["outdir"], output['html'])
		rename_out(input["fastq"], ["_fastqc.zip"], params["outdir"], output['gzip'])

rule fastqc_pe_pre:
	input:
		fastq=lambda wildcards: config["samples"][wildcards.sample]
	output:
		html=expand(RESULTS_PATH+"/fastqc-pre/{{sample}}_{ext}_fastqc.html", ext=["F", "R"]),
		gzip=temp(expand(RESULTS_PATH+"/fastqc-pre/{{sample}}_{ext}_fastqc.zip", ext=["F", "R"]))
	params:
		outdir=RESULTS_PATH+"/fastqc-pre",
		cluster='-N 1 -c 2 --mem=8G -t 160:00:00 -o {}/logs/fastqc-pre.{{sample}}.%A.log'.format(RESULTS_PATH)
	log:
		RESULTS_PATH+"/logs/fastqc-pre/{sample}.txt"
	threads:
		2
	run:
		shell("fastqc -t {threads} --outdir {params.outdir} {input.fastq} 2>&1 > {log}")
		rename_out(input["fastq"], ["_fastqc.html"], params["outdir"], output['html'])
		rename_out(input["fastq"], ["_fastqc.zip"], params["outdir"], output['gzip'])

rule trimgalore_se:
	input:
		fastq=lambda wildcards: config["samples"][wildcards.sample]
	output:
		fastq=temp(expand(RESULTS_PATH+"/trim_galore/{{sample}}_{ext}_trimmed.fq.gz", ext=["SE"]))
	params:
		basic="-q 20 --gzip --length 16 --no_report_file",
		outdir=RESULTS_PATH+"/trim_galore",
		cluster='-N 1 -c 1 --mem=16G -t 160:00:00 -o {}/logs/trim_galore.{{sample}}.%A.log'.format(RESULTS_PATH)
	log:
		RESULTS_PATH+"/logs/trim_galore/{sample}.fq.gz_trimming_report.txt",
	run:
		shell("trim_galore {params.basic} -o {params.outdir} {input.fastq} &> {log}")
		rename_out(input["fastq"], ["_trimmed.fq.gz"], params["outdir"], output['fastq'])

rule trimgalore_pe:
	input:
		fastq=lambda wildcards: config["samples"][wildcards.sample]
	output:
		fastq=temp(expand(RESULTS_PATH+"/trim_galore/{{sample}}_{ext}_trimmed.fq.gz", ext=["F", "R"]))
	params:
		basic="-q 20 --gzip --length 16 --no_report_file --paired --trim1",
		outdir=RESULTS_PATH+"/trim_galore",
		cluster='-N 1 -c 1 --mem=16G -t 160:00:00 -o {}/logs/trim_galore.{{sample}}.%A.log'.format(RESULTS_PATH)
	log:
		RESULTS_PATH+"/logs/trim_galore/{sample}.fq.gz_trimming_report.txt"
	run:
		shell("trim_galore {params.basic} -o {params.outdir} {input.fastq} &> {log}")
		rename_out(input["fastq"], ["_val_1.fq.gz", "_val_2.fq.gz"], params["outdir"], output['fastq'])

rule index_rRNA_tRNA:
	input:
		"genome/human_rRNA_tRNA/rRNA_tRNA.fa.gz"
	output:
		expand("genome/human_rRNA_tRNA/rRNA_tRNA.{count}.bt2", count=['1', '2', '3', '4']),
		expand("genome/human_rRNA_tRNA/rRNA_tRNA.rev.{count}.bt2", count=['1', '2'])
	params:
		basename="genome/human_rRNA_tRNA/rRNA_tRNA",
		cluster='-N 1 -c 8 --mem=30G -t 160:00:00'
	log:
		"logs/index_rRNA_tRNA/index_rRNA_tRNA.log"
	threads:
		8
	shell:
		"bowtie2-build --threads {threads} {input} {params.basename} &> {log}"

rule remove_rRNA_tRNA_se:
	input:
		fastq=expand(RESULTS_PATH+"/trim_galore/{{sample}}_{ext}_trimmed.fq.gz", ext=["SE"]),
		index1=expand("genome/human_rRNA_tRNA/rRNA_tRNA.{count}.bt2", count=['1', '2', '3', '4']),
		index2=expand("genome/human_rRNA_tRNA/rRNA_tRNA.rev.{count}.bt2", count=['1', '2'])
	output:
		# fastq=temp(expand(RESULTS_PATH+"/rRNA_tRNA_removed/{{sample}}_{ext}_rRNA_tRNA_removed.fq.gz", ext=["SE"])),
		fastq=temp(expand(RESULTS_PATH+"/rRNA_tRNA_removed/{{sample}}_{ext}_rRNA_tRNA_removed.fq.gz", ext=["SE"])),
		tmp=temp(RESULTS_PATH+"/rRNA_tRNA_removed/{sample}.tmp")
	params:
		basic="--sensitive-local",
		cluster='-N 1 -c 8 --mem=16G -t 160:00:00 -o {}/logs/rRNA_tRNA_removed.{{sample}}.%A.log'.format(RESULTS_PATH)
	log:
		RESULTS_PATH+"/logs/rRNA_tRNA_removed/{sample}_rRNA_tRNA_removed.log"
	threads:
		8
	shell:
		"bowtie2 {params.basic} --threads {threads} --un-gz {output.fastq} -x genome/human_rRNA_tRNA/rRNA_tRNA -U {input.fastq} 1> {output.tmp} 2> {log}"

rule remove_rRNA_tRNA_pe:
	input:
		fastq=expand(RESULTS_PATH+"/trim_galore/{{sample}}_{ext}_trimmed.fq.gz", ext=["F", "R"]),
		index1=expand("genome/human_rRNA_tRNA/rRNA_tRNA.{count}.bt2", count=['1', '2', '3', '4']),
		index2=expand("genome/human_rRNA_tRNA/rRNA_tRNA.rev.{count}.bt2", count=['1', '2'])
	output:
		# fastq=temp(expand(RESULTS_PATH+"/rRNA_tRNA_removed/{{sample}}_{ext}_rRNA_tRNA_removed.fq.gz", ext=["F", "R"])),
		fastq=temp(expand(RESULTS_PATH+"/rRNA_tRNA_removed/{{sample}}_{ext}_rRNA_tRNA_removed.fq.gz", ext=["F", "R"])),
		tmp=temp(RESULTS_PATH+"/rRNA_tRNA_removed/{sample}.tmp")
	params:
		basic="--sensitive-local",
		outname=RESULTS_PATH+"/rRNA_tRNA_removed/{sample}.fq.gz",
		outdir=RESULTS_PATH+"/rRNA_tRNA_removed",
		cluster='-N 1 -c 8 --mem=16G -t 160:00:00 -o {}/logs/rRNA_tRNA_removed.{{sample}}.%A.log'.format(RESULTS_PATH)
	log:
		RESULTS_PATH+"/logs/rRNA_tRNA_removed/{sample}_rRNA_tRNA_removed.log"
	threads:
		8
	run:
		fq1 = input["fastq"][0] 
		fq2 = input["fastq"][1] 
		shell("bowtie2 {params.basic} -p {threads} --un-conc-gz {params.outname} --met-file {log} -x genome/human_rRNA_tRNA/rRNA_tRNA -1 {fq1} -2 {fq2} 1> {output.tmp} 2> {log}")
		rename_out([params["outname"], params["outname"]], [".fq.1.gz", ".fq.2.gz"], params["outdir"], output['fastq'])	

rule fastqc_se_post:
	input:
		fastq=expand(RESULTS_PATH+"/rRNA_tRNA_removed/{{sample}}_{ext}_rRNA_tRNA_removed.fq.gz", ext=["SE"])
	output:
		html=expand(RESULTS_PATH+"/fastqc-post/{{sample}}_{ext}_fastqc.html", ext=["SE"]),
		gzip=temp(expand(RESULTS_PATH+"/fastqc-post/{{sample}}_{ext}_fastqc.zip", ext=["SE"]))
	params:
		outdir=RESULTS_PATH+"/fastqc-post",
		cluster='-N 1 -c 1 --mem=8G -t 160:00:00 -o {}/logs/fastqc-post.{{sample}}.%A.log'.format(RESULTS_PATH)
	log:
		RESULTS_PATH+"/logs/fastqc-post/{sample}.txt"
	threads:
		1
	run:
		shell("fastqc -t {threads} --outdir {params.outdir} {input.fastq} 2>&1 > {log}")
		rename_out(input["fastq"], ["_fastqc.html"], params["outdir"], output['html'])
		rename_out(input["fastq"], ["_fastqc.zip"], params["outdir"], output['gzip'])

rule fastqc_pe_post:
	input:
		fastq=expand(RESULTS_PATH+"/rRNA_tRNA_removed/{{sample}}_{ext}_rRNA_tRNA_removed.fq.gz", ext=["F", "R"])
	output:
		html=expand(RESULTS_PATH+"/fastqc-post/{{sample}}_{ext}_fastqc.html", ext=["F", "R"]),
		gzip=temp(expand(RESULTS_PATH+"/fastqc-post/{{sample}}_{ext}_fastqc.zip", ext=["F", "R"]))
	params:
		outdir=RESULTS_PATH+"/fastqc-post",
		cluster='-N 1 -c 2 --mem=8G -t 160:00:00 -o {}/logs/fastqc-post.{{sample}}.%A.log'.format(RESULTS_PATH)
	log:
		RESULTS_PATH+"/logs/fastqc-post/{sample}.txt"
	threads:
		2
	run:
		shell("fastqc -t {threads} --outdir {params.outdir} {input.fastq} 2>&1 > {log}")
		rename_out(input["fastq"], ["_fastqc.html"], params["outdir"], output['html'])
		rename_out(input["fastq"], ["_fastqc.zip"], params["outdir"], output['gzip'])

rule gunzip_annotation:
	input:
		ANNOTATION_PATH
	output:
		os.path.splitext(ANNOTATION_PATH)[0]
	params:
		cluster='-N 1 -c 1 --mem=8G -t 160:00:00'
	shell:
		"gunzip {input}"

rule gunzip_genome:
	input:
		GENOME_PATH
	output:
		os.path.splitext(GENOME_PATH)[0]
	params:
		cluster='-N 1 -c 1 --mem=8G -t 160:00:00'
	shell:
		"gunzip {input}"

rule index_star:
	input:
		genome=os.path.splitext(GENOME_PATH)[0] if os.path.splitext(GENOME_PATH)[1] == ".gz" else GENOME_PATH,
		annotation=os.path.splitext(ANNOTATION_PATH)[0] if os.path.splitext(ANNOTATION_PATH)[1] == ".gz" else ANNOTATION_PATH
	output:
		outdir=STAR_INDEX_PATH,
		outfile=STAR_INDEX_PATH+"/SA",
		index=STAR_INDEX_PATH+"/SAindex",
		chrmlen=STAR_INDEX_PATH+"/chrNameLength.txt"
	params:
		overhang="--sjdbOverhang 99",
		cluster='-N 1 -c 8 --mem=64G -t 160:00:00'
	threads:
		8
	run:
		shell("STAR --runMode genomeGenerate --runThreadN {threads} --genomeDir {output.outdir} --genomeFastaFiles {input.genome} --sjdbGTFfile {input.annotation} {params.overhang}")
		# shell("gzip {input.genome}")
		# shell("gzip {input.annotation}")

rule map_star_se:
	input:
		fastq=expand(RESULTS_PATH+"/rRNA_tRNA_removed/{{sample}}_{ext}_rRNA_tRNA_removed.fq.gz", ext=["SE"]),
		genome=STAR_INDEX_PATH,
		index=STAR_INDEX_PATH+"/SAindex",
		chrmlen=STAR_INDEX_PATH+"/chrNameLength.txt"
	output:
		# bam=temp(expand(RESULTS_PATH+"/mapped/{{sample}}_{ext}.Aligned.sortedByCoord.out.bam", ext=["SE"])),
		bam=expand(RESULTS_PATH+"/mapped/{{sample}}_{ext}.Aligned.sortedByCoord.out.bam", ext=["SE"]),
		cnt=expand(RESULTS_PATH+"/mapped/{{sample}}_{ext}.ReadsPerGene.out.tab", ext=["SE"]),
		jct=expand(RESULTS_PATH+"/mapped/{{sample}}_{ext}.SJ.out.tab", ext=["SE"]),
		# std=expand(RESULTS_PATH+"/mapped/{{sample}}_{ext}.StrandCheck.out.tab", ext=["SE"]),
		wig=temp(expand(RESULTS_PATH+"/mapped/{{sample}}_{ext}.Signal.Unique.str{num}.out.wig", ext=["SE"], num=["1", "2"])),
		mul=temp(expand(RESULTS_PATH+"/mapped/{{sample}}_{ext}.Signal.UniqueMultiple.str{num}.out.wig", ext=["SE"], num=["1", "2"])),
		# bwi=expand(RESULTS_PATH+"/coverage/{{sample}}_{ext}_{typ}.bigwig", ext=["SE"], typ=["plus", "minus"]),
		# bgu=temp(expand(RESULTS_PATH+"/coverage/{{sample}}_{ext}.bedGraph", ext=["SE"])),
		# bwu=expand(RESULTS_PATH+"/coverage/{{sample}}_{ext}.bigwig", ext=["SE"]),
		log=expand(RESULTS_PATH+"/mapped/{{sample}}_{ext}.Log.final.out", ext=["SE"])
	params:
		outdir=RESULTS_PATH+"/mapped",
		alignemnt="--readFilesCommand zcat --genomeLoad NoSharedMemory --twopassMode Basic --alignSJoverhangMin 8 --alignSJDBoverhangMin 1 --sjdbScore 1 --limitBAMsortRAM 60000000000",
		rna="--alignIntronMin 20 --alignIntronMax 1000000 --alignMatesGapMax 1000000 --quantMode GeneCounts",
		dna="--alignIntronMax 1 --alignMatesGapMax 300",
		output="--outFilterMultimapNmax 1 --outFilterMismatchNmax 999 --outFilterMismatchNoverReadLmax 0.04 --outFilterType BySJout  --outSAMattributes All --outSAMstrandField intronMotif --outSAMtype BAM SortedByCoordinate --outWigType wiggle --outWigStrand Stranded --outWigNorm RPM",
		cluster='-N 1 -c 8 --mem=64G -t 160:00:00 -o {}/logs/mapped.{{sample}}.%A.log'.format(RESULTS_PATH)
	log:
		expand(RESULTS_PATH+"/logs/star_mapped/{{sample}}_{ext}.txt", ext=["SE"])
	threads:
		8
	run:
		prefix = "/".join((params["outdir"], os.path.basename(output["bam"][0]).partition(".")[0]+"."))
		if config['seq_type'] == "RNAseq":
			shell("STAR --runMode alignReads --runThreadN {threads} --genomeDir {input.genome} --readFilesIn {input.fastq} --outFileNamePrefix {prefix} {params.alignemnt} {params.rna} {params.output} 2>&1 > {log}")

			# create_bigWig(platform_info(), output["cnt"][0], output["std"][0], output["wig"], input["chrmlen"], output["bwi"], output["bgu"][0], output["bwu"][0])
	
		elif config['seq_type'] == "ChIPseq":
			shell("STAR --runMode alignReads --runThreadN {threads} --genomeDir {input.genome} --readFilesIn {input.fastq} --outFileNamePrefix {prefix} {params.alignemnt} {params.dna} {params.output} 2>&1 > {log}")

rule map_star_pe:
	input:
		fastq=expand(RESULTS_PATH+"/rRNA_tRNA_removed/{{sample}}_{ext}_rRNA_tRNA_removed.fq.gz", ext=["F", "R"]),
		genome=STAR_INDEX_PATH,
		index=STAR_INDEX_PATH+"/SAindex",
		chrmlen=STAR_INDEX_PATH+"/chrNameLength.txt"
	output:
		# bam=temp(expand(RESULTS_PATH+"/mapped/{{sample}}_{ext}.Aligned.sortedByCoord.out.bam", ext=["PE"])),
		bam=expand(RESULTS_PATH+"/mapped/{{sample}}_{ext}.Aligned.sortedByCoord.out.bam", ext=["PE"]),
		cnt=expand(RESULTS_PATH+"/mapped/{{sample}}_{ext}.ReadsPerGene.out.tab", ext=["PE"]),
		jct=expand(RESULTS_PATH+"/mapped/{{sample}}_{ext}.SJ.out.tab", ext=["PE"]),
		# std=expand(RESULTS_PATH+"/mapped/{{sample}}_{ext}.StrandCheck.out.tab", ext=["PE"]),
		wig=temp(expand(RESULTS_PATH+"/mapped/{{sample}}_{ext}.Signal.Unique.str{num}.out.wig", ext=["PE"], num=["1", "2"])),
		mul=temp(expand(RESULTS_PATH+"/mapped/{{sample}}_{ext}.Signal.UniqueMultiple.str{num}.out.wig", ext=["PE"], num=["1", "2"])),
		# bwi=expand(RESULTS_PATH+"/coverage/{{sample}}_{ext}_{typ}.bigwig", ext=["PE"], typ=["plus", "minus"]),
		# bgu=temp(expand(RESULTS_PATH+"/coverage/{{sample}}_{ext}.bedGraph", ext=["PE"])),
		# bwu=expand(RESULTS_PATH+"/coverage/{{sample}}_{ext}.bigwig", ext=["PE"]),
		log=expand(RESULTS_PATH+"/mapped/{{sample}}_{ext}.Log.final.out", ext=["PE"])
	params:
		outdir=RESULTS_PATH+"/mapped",
		alignemnt="--readFilesCommand zcat --genomeLoad NoSharedMemory --twopassMode Basic --alignSJoverhangMin 8 --alignSJDBoverhangMin 1 --sjdbScore 1 --limitBAMsortRAM 60000000000",
		rna="--alignIntronMin 20 --alignIntronMax 1000000 --alignMatesGapMax 1000000 --quantMode GeneCounts",
		dna="--alignIntronMax 1 --alignMatesGapMax 300",
		output="--outFilterMultimapNmax 1 --outFilterMismatchNmax 999 --outFilterMismatchNoverReadLmax 0.04 --outFilterType BySJout  --outSAMattributes All --outSAMstrandField intronMotif --outSAMtype BAM SortedByCoordinate --outWigType wiggle --outWigStrand Stranded --outWigNorm RPM",
		cluster='-N 1 -c 8 --mem=64G -t 160:00:00 -o {}/logs/mapped.{{sample}}.%A.log'.format(RESULTS_PATH)
	log:
		expand(RESULTS_PATH+"/logs/star_mapped/{{sample}}_{ext}.txt", ext=["PE"])
	threads:
		8
	run:
		prefix = "/".join((params["outdir"], os.path.basename(output["bam"][0]).partition(".")[0]+"."))
		if config['seq_type'] == "RNAseq":
			shell("STAR --runMode alignReads --runThreadN {threads} --genomeDir {input.genome} --readFilesIn {input.fastq} --outFileNamePrefix {prefix} {params.alignemnt} {params.rna} {params.output} 2>&1 > {log}")

			# create_bigWig(platform_info(), output["cnt"][0], output["std"][0], output["wig"], input["chrmlen"], output["bwi"], output["bgu"][0], output["bwu"][0])
	
		elif config['seq_type'] == "ChIPseq":
			shell("STAR --runMode alignReads --runThreadN {threads} --genomeDir {input.genome} --readFilesIn {input.fastq} --outFileNamePrefix {prefix} {params.alignemnt} {params.dna} {params.output} 2>&1 > {log}")

def create_bigWig(exe_path, counts, outfile, wiglist, chrmlen, biglist, bedg, bigw):
	df = pd.read_table(counts, sep="\t", index_col=0, names=["Unstranded", "FirstStrand", "SecondStrand"])
	df = df.filter(regex="^(?!N_)", axis=0, ).sum()

	with open(outfile, "w") as of:
		if df['FirstStrand']/(df['FirstStrand']+df['SecondStrand']) > 0.55 :
			of.write("FirstStrand")
			shell(" ".join(("executables/"+exe_path+"/wigToBigWig", wiglist[0], chrmlen, biglist[0])))
			shell(" ".join(("executables/"+exe_path+"/wigToBigWig", wiglist[1], chrmlen, biglist[1])))
		elif df['FirstStrand']/(df['FirstStrand']+df['SecondStrand']) < 0.45 :
			of.write("SecondStrand")
			shell(" ".join(("executables/"+exe_path+"/wigToBigWig", wiglist[1], chrmlen, biglist[0])))
			shell(" ".join(("executables/"+exe_path+"/wigToBigWig", wiglist[0], chrmlen, biglist[1])))
		else:
			of.write("Unstranded")
			shell(" ".join(("executables/"+exe_path+"/wigToBigWig", wiglist[0], chrmlen, biglist[0])))
			shell(" ".join(("executables/"+exe_path+"/wigToBigWig", wiglist[1], chrmlen, biglist[1])))

	shell(" ".join(("executables/"+exe_path+"/bigWigMerge", *biglist, bedg)))
	shell(" ".join(("LC_COLLATE=C sort -k1,1 -k2,2n", bedg, ">", os.path.splitext(bedg)[0]+".sorted")))
	shell(" ".join(("mv", os.path.splitext(bedg)[0]+".sorted", bedg)))
	shell(" ".join(("executables/"+exe_path+"/bedGraphToBigWig", bedg, chrmlen, bigw)))

	return(0)

rule wigToBigWig_se:
	input:
		wig=expand(RESULTS_PATH+"/mapped/{{sample}}_{ext}.Signal.Unique.str{num}.out.wig", ext=["SE"], num=["1", "2"]),
		cnt=expand(RESULTS_PATH+"/mapped/{{sample}}_{ext}.ReadsPerGene.out.tab", ext=["SE"]),
		chrmlen="genome/STAR_GRCh38_v27/chrNameLength.txt"
	output:
		std=expand(RESULTS_PATH+"/mapped/{{sample}}_{ext}.StrandCheck.out.tab", ext=["SE"]),
		bwi=expand(RESULTS_PATH+"/coverage/{{sample}}_{ext}_{typ}.bigwig", ext=["SE"], typ=["plus", "minus"]),
		bgu=temp(expand(RESULTS_PATH+"/coverage/{{sample}}_{ext}.bedGraph", ext=["SE"])),
		bwu=expand(RESULTS_PATH+"/coverage/{{sample}}_{ext}.bigwig", ext=["SE"])
	params:
		cluster='-N 1 -c 1 --mem=32G -t 160:00:00 -o {}/logs/coverage.{{sample}}.%A.log'.format(RESULTS_PATH)
	log:
		expand(RESULTS_PATH+"/logs/wigToBigWig/{{sample}}_{ext}.txt", ext=["SE"])
	threads:
		1
	run:
		create_bigWig(platform_info(), input["cnt"][0], output["std"][0], input["wig"], input["chrmlen"], output["bwi"], output["bgu"][0], output["bwu"][0])

rule wigToBigWig_pe:
	input:
		wig=expand(RESULTS_PATH+"/mapped/{{sample}}_{ext}.Signal.Unique.str{num}.out.wig", ext=["PE"], num=["1", "2"]),
		cnt=expand(RESULTS_PATH+"/mapped/{{sample}}_{ext}.ReadsPerGene.out.tab", ext=["PE"]),
		chrmlen="genome/STAR_GRCh38_v27/chrNameLength.txt"
	output:
		std=expand(RESULTS_PATH+"/mapped/{{sample}}_{ext}.StrandCheck.out.tab", ext=["PE"]),
		bwi=expand(RESULTS_PATH+"/coverage/{{sample}}_{ext}_{typ}.bigwig", ext=["PE"], typ=["plus", "minus"]),
		bgu=temp(expand(RESULTS_PATH+"/coverage/{{sample}}_{ext}.bedGraph", ext=["PE"])),
		bwu=expand(RESULTS_PATH+"/coverage/{{sample}}_{ext}.bigwig", ext=["PE"])
	params:
		cluster='-N 1 -c 1 --mem=32G -t 160:00:00 -o {}/logs/coverage.{{sample}}.%A.log'.format(RESULTS_PATH)
	log:
		expand(RESULTS_PATH+"/logs/wigToBigWig/{{sample}}_{ext}.txt", ext=["PE"])
	threads:
		1
	run:
		create_bigWig(platform_info(), input["cnt"][0], output["std"][0], input["wig"], input["chrmlen"], output["bwi"], output["bgu"][0], output["bwu"][0])

rule stringtie_se:
	input:
		bam=expand(RESULTS_PATH+"/mapped/{{sample}}_{ext}.Aligned.sortedByCoord.out.bam", ext=["SE"]),
		std=expand(RESULTS_PATH+"/mapped/{{sample}}_{ext}.StrandCheck.out.tab", ext=["SE"]),
		annotation=os.path.splitext(config["annotation_path"])[0] if os.path.splitext(config["annotation_path"])[1] == ".gz" else config["annotation_path"]
	output:
		gtf=expand(RESULTS_PATH+"/stringtie/{{sample}}_{ext}.StringTie.gtf", ext=["SE"]),
		exp=expand(RESULTS_PATH+"/stringtie/{{sample}}_{ext}.geneAbundance.gtf", ext=["SE"])
	params:
		basic="-f 0.2 -m 200 -a 10 -j 3 -C",
		cluster='-N 1 -c 8 --mem=32G -t 160:00:00 -o {}/logs/stringtie.{{sample}}.%A.log'.format(RESULTS_PATH)
	log:
		expand(RESULTS_PATH+"/logs/stringtie/{{sample}}_{ext}.txt", ext=["SE"])
	threads:
		8
	run:
		with open(input["std"], "r") as infile:
			first_line = infile.readline()
		if first_line == "FirstStrand":
			strand = "--rf"
		elif first_line == "SecondStrand":
			strand = "--fr"
		else:
			strand = ""
		# shell("executables/"+platform_info()+"/stringtie {input.bam} -G {input.annotation} {strand} -o {output.gtf} -p {threads} -A {output.exp} {params.basic} > {log}")

rule stringtie_pe:
	input:
		bam=expand(RESULTS_PATH+"/mapped/{{sample}}_{ext}.Aligned.sortedByCoord.out.bam", ext=["PE"]),
		std=expand(RESULTS_PATH+"/mapped/{{sample}}_{ext}.StrandCheck.out.tab", ext=["PE"]),
		annotation=os.path.splitext(config["annotation_path"])[0] if os.path.splitext(config["annotation_path"])[1] == ".gz" else config["annotation_path"]
	output:
		gtf=expand(RESULTS_PATH+"/stringtie/{{sample}}_{ext}.StringTie.gtf", ext=["PE"]),
		exp=expand(RESULTS_PATH+"/stringtie/{{sample}}_{ext}.geneAbundance.gtf", ext=["PE"])
	params:
		basic="-f 0.2 -m 200 -a 10 -j 3 -C ",
		cluster='-N 1 -c 8 --mem=32G -t 160:00:00 -o {}/logs/stringtie.{{sample}}.%A.log'.format(RESULTS_PATH)
	log:
		expand(RESULTS_PATH+"/logs/stringtie/{{sample}}_{ext}.txt", ext=["PE"])
	threads:
		8
	run:
		with open(input["std"], "r") as infile:
			first_line = infile.readline()
		if first_line == "FirstStrand":
			strand = "--rf"
		elif first_line == "SecondStrand":
			strand = "--fr"
		else:
			strand = ""	
		shell("executables/"+platform_info()+"/stringtie {input.bam} -G {input.annotation} {strand} -o {output.gtf} -p {threads} -A {output.exp} {params.basic} > {log}")

rule sambamba_index:
	input:
		RESULTS_PATH+"/mapped/{sample}.Aligned.sortedByCoord.out.bam"
	output:
		RESULTS_PATH+"/mapped/{sample}.Aligned.sortedByCoord.out.bam.bai"
	params:
		cluster='-N 1 -c 8 --mem=32G -t 160:00:00'
	threads:
		8
	shell:
		"sambamba index -t {threads} {input} {output}"

rule remove_duplicate:
	input:
		picard="executables/jar/picard.jar",
		bamfile=RESULTS_PATH+"/mapped/{sample}.Aligned.sortedByCoord.out.bam",
		index=RESULTS_PATH+"/mapped/{sample}.Aligned.sortedByCoord.out.bam.bai"
	output:
		RESULTS_PATH+"/picarded/{sample}.Aligned.sortedByCoord.picard.bam",
	log:
		RESULTS_PATH+"/log/remove_duplicate/{sample}.Aligned.sortedByCoord.picard.txt"
	params:
		pd="REMOVE_DUPLICATES=true ASSUME_SORT_ORDER=coordinate",
		cluster='-N 1 -c 1 --mem=32G -t 160:00:00'
	shell:
		"java -Xmx16G -jar {input.picard} MarkDuplicates I={input.bamfile} O={output} M={log} {params.pd}"

rule picard_index:
	input:
		picard="executables/jar/picard.jar",
		bam=RESULTS_PATH+"/picarded/{sample}.Aligned.sortedByCoord.picard.bam"
	output:
		RESULTS_PATH+"/picarded/{sample}.Aligned.sortedByCoord.picard.bam.bai"
	params:
		cluster='-N 1 -c 1 --mem=16G -t 160:00:00'
	shell:
		"java -Xmx16G -jar {input.picard} BuildBamIndex I={input.bam} O={output}"

rule create_flatGFF:
	input:
		ann=os.path.splitext(config["annotation_path"])[0] if os.path.splitext(config["annotation_path"])[1] == ".gz" else config["annotation_path"],
		exe="executables/jar/QoRTs.jar"
	output:
		config["annotation_path"].replace(".gtf", ".flat.gtf")
	params:
		cluster='-N 1 -c 1 --mem=16G -t 160:00:00'
	shell:
		"java -Xmx16G -jar {input.exe} makeFlatGff --stranded {input.ann} {output}"

# rule quantification:
# 	input:
# #		executable="QoRTs.jar",
# 		gff="annotation/gencode.v27.annotation.gtf.gz",
# 		flatfile="annotation/gencode.v27.annotation.flat.gtf.gz",
# 		bamfile=RESULTS_PATH+"/picarded/{sample}.Aligned.sortedByCoord.picard.bam",
# 		index=RESULTS_PATH+"/picarded/{sample}.Aligned.sortedByCoord.picard.bam.bai",
# 		chrmlen="genome/STAR_GRCh38_v27/chrNameLength.txt"
# 	output:
# 		firstStrand=RESULTS_PATH+"/qorts/{sample}.firstStrand.counts",
# 		secondStrand=RESULTS_PATH+"/qorts/{sample}.secondStrand.counts"
# 	params:
# 		library="--stranded --singleEnded --minMAPQ 255",
# 		functions="StrandCheck,GeneCalcs,writeKnownSplices,writeNovelSplices,chromCounts,writeGenewiseGeneBody,writeBiotypeCounts,calcDetailedGeneCounts,makeWiggles,writeDESeq,writeDEXSeq,writeJunctionSeqCounts",
# 		cluster='-N 1 -c 1 --mem=16G -t 160:00:00'
# 	shell:
# 		"""
# 		java -Xmx16G -jar QoRTs.jar QC {params.library} --runFunctions {params.functions} --chromSizes {input.chrmlen} {input.bamfile} {input.gff} {output.firstStrand}
# 		java -Xmx16G -jar QoRTs.jar QC {params.library} --stranded_fr_secondstrand --runFunctions {params.functions} --chromSizes {input.chrmlen} {input.bamfile} {input.gff} {output.secondStrand}
# 		"""

# rule genome_coverage:
# 	input:
# 		bamfile="picarded/{sample}.Aligned.sortedByCoord.picard.bam",
# 		genomeSize="genome/STAR_GRCh38_v27/chrNameLength.txt"
# 	output:
# 		positive="coverage/{sample}.pos.bedGraph",
# 		negative="coverage/{sample}.neg.bedGraph"
# 	params:
# 		bt="-bg -split",
# 		cluster='-N 1 -c 1 --mem=24G -t 160:00:00'
# 	shell:
# 		"""
# 		genomeCoverageBed {params.bt} -strand + -ibam {input.bamfile} -g {input.genomeSize} > {output.positive}
# 		genomeCoverageBed {params.bt} -strand - -ibam {input.bamfile} -g {input.genomeSize} > {output.negative}
# 		"""

rule report:
	input:
		preqc=expand(RESULTS_PATH+"/fastqc-pre/{}_{}_fastqc.html".format(sample, ext) for sample in config["samples"] for ext in ( ["F", "R"] if len(config["samples"][sample])==2 else ["SE"] )),
		postqc=expand(RESULTS_PATH+"/fastqc-post/{}_{}_fastqc.html".format(sample, ext) for sample in config["samples"] for ext in ( ["F", "R"] if len(config["samples"][sample])==2 else ["SE"] )),
		bam=expand(RESULTS_PATH+"/mapped/{}_{}.Aligned.sortedByCoord.out.bam".format(sample, ext) for sample in config["samples"] for ext in ( ["PE"] if len(config["samples"][sample])==2 else ["SE"] )),
		bigwig=expand(RESULTS_PATH+"/coverage/{}_{}.bigwig".format(sample, ext) for sample in config["samples"] for ext in ( ["PE"] if len(config["samples"][sample])==2 else ["SE"] )),
		stringtie=expand(RESULTS_PATH+"/stringtie/{}_{}.StringTie.gtf".format(sample, ext) for sample in config["samples"] for ext in ( ["PE"] if len(config["samples"][sample])==2 else ["SE"] ))
	output:
		"report.html"
	run:
		# pd.DataFrame({"FastQC (pre)" : preqc, "FastQC (post)": postqc, "BamFile" : bam, "BigWig": bigwig, "StringTie (GTF)", stringtie})

		from snakemake.utils import report
		report("""
		RNA-seq workflow
		===================================

		Reads were mapped to the Human reference genome GRCh38 using the Gencode annotation version 27.

		""", output[0], **input)
